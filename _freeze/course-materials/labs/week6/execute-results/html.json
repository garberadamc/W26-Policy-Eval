{
  "hash": "7635a43f60ff906497994091891ced6d",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Lab Week 6: Instrumental Variables\"\nsubtitle: \"\"\nauthor: \"EDS 241 / ESM 244\"\nformat:\n  html\ndate: \"February 13, 2026\"\n---\n\n\n\n\n# Instrumental Variables Review\n\n## The Endogeneity Problem\n\nIn many research settings we want to estimate the causal effect of some treatment $D$ on an outcome $Y$. A naive OLS regression of $Y$ on $D$ gives us an unbiased estimate **only** if $D$ is uncorrelated with the error term $\\varepsilon$. When that assumption fails — i.e., when $\\text{Cov}(D, \\varepsilon) \\neq 0$ — we say $D$ is **endogenous**, and OLS is biased.\n\nEndogeneity can arise from several sources:\n\n- **Omitted variable bias**: An unobserved variable affects both $D$ and $Y$.\n- **Simultaneity / reverse causality**: $Y$ also influences $D$.\n- **Measurement error**: $D$ is measured with noise.\n\n## The IV Solution\n\nAn **instrumental variable** $Z$ allows us to isolate the part of the variation in $D$ that is *exogenous* — i.e., uncorrelated with the error term — and use only that part to estimate the effect of $D$ on $Y$.\n\nFor $Z$ to be a valid instrument it must satisfy two conditions:\n\n1. **Relevance**: $Z$ must be correlated with the endogenous treatment $D$.\n$$\\text{Cov}(Z, D) \\neq 0$$\n\n2. **Exclusion restriction**: $Z$ must affect $Y$ *only* through $D$ — it cannot have a direct effect on $Y$ or be correlated with unobserved determinants of $Y$.\n$$\\text{Cov}(Z, \\varepsilon) = 0$$\n\nThe relevance condition is testable (we can check whether $Z$ predicts $D$ in a regression). The exclusion restriction is **not directly testable** and must be argued theoretically.\n\n## Two-Stage Least Squares (2SLS)\n\nThe most common IV estimator is **Two-Stage Least Squares (2SLS)**:\n\n**First stage**: Regress the endogenous treatment on the instrument(s) and any exogenous controls:\n$$D_i = \\beta_0 + \\beta_1 Z_i$$ \nwhere $W$ are exogenous control variables. Save the predicted values $\\hat{D}$.\n\n**Second stage**: Regress the outcome on the predicted values from the first stage and the same controls:\n$$Y_i = \\beta_0 + \\beta_1 \\hat{D}_i$$ \n\n\n:::{.callout-important}\nWhen performing 2SLS manually (running two separate regressions), the standard errors from the second stage are incorrect because they don't account for the fact that $\\hat{D}$ is itself estimated. In practice we use dedicated functions like `ivreg()` that compute correct standard errors. We'll do both in this lab so you can see the mechanics, but always report results from the dedicated IV estimator.\n:::\n\n# Lab Overview\n\n## Research Question\n\n**Does air pollution (PM2.5) increase respiratory illness?**\n\n\n- $Y$ (outcome): Google Trends search interest for \"asthma inhaler\" — our proxy for respiratory illness\n- $X$ (endogenous regressor): Weekly mean PM2.5 concentration (AQI)\n- $Z$ (instrument): Weekly total precipitation\n\n## The Endogeneity Problem in Our Setting\n\nIf we simply regress our measure of respiratory illness ($Y$) on PM2.5 concentrations ($X$), our estimate will likely be biased. \n\n:::{.callout-tip title=\"Comprehension Check\"}\nWhat are the potential sources of endogeneity?\n:::\n\n## Our Instrument: Precipitation\n\nWe propose using **weekly precipitation** as an instrument ($Z$) for PM2.5 ($D$). The logic:\n\n- **Relevance**: Rainfall is a mechanism for removing particulate matter from the atmosphere (\"wet deposition\"). Weeks with more rain should have lower PM2.5 — we can test this.\n- **Exclusion restriction**: Rainfall affects asthma inhaler searches ($Y$) *only* through its effect on air quality ($D$), not directly. This is the assumption we must argue. It is more plausible if we control for seasonal patterns (month fixed effects), since precipitation's main pathway to respiratory outcomes is through air quality.\n\n:::{.callout-warning}\nThe exclusion restriction is not bulletproof. One could argue that wet weather keeps people indoors (changing exposure patterns) or that humidity itself triggers asthma. We include month fixed effects to absorb seasonal confounders, but you should always think critically about remaining threats.\n:::\n\n\n## Data Sources\n\nWe combine three datasets for Los Angeles County in 2023:\n\n| Dataset | Source | Frequency | Key Variable |\n|---------|--------|-----------|--------------|\n| PM2.5 concentrations | EPA Air Quality System (AQS) | Daily | AQI (Air Quality Index) |\n| Precipitation | NOAA GHCN-D (station USC00045933, Downtown LA) | Daily | Precipitation (tenths of mm) |\n| Respiratory illness proxy | Google Trends (\"asthma inhaler\", LA DMA) | Weekly | Search interest index (0–100) |\n\nSince Google Trends data is weekly, we will aggregate all daily data to the weekly level before merging.\n\n\n:::{.callout-tip title=\"Comprehension Check\"}\n1. What omitted variables could drive both PM2.5 and asthma searches upward simultaneously?\n2. Can you think of a scenario in which precipitation might violate the exclusion restriction even after controlling for month fixed effects?\n:::\n\n\n\n# Analysis\n\n## Setup\n\n#### Load Packages\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#install.packages(\"gtrendsR\") \n#install.packages(\"ivreg\")\n#remotes::install_github(\"ropensci/rnoaa\")\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(gtrendsR)     # For getting google trends data\nlibrary(ivreg)        # For 2SLS\nlibrary(lubridate)    # Date handling\nlibrary(rnoaa)        # NOAA weather data\nlibrary(jtools)\n\nset.seed(241244)\n```\n:::\n\n\n\n#### Load in Data\n\nWe'll use LA County 2023 data for PM2.5 and precipitation from EPA's AQS.\n\n\n::: {.cell}\n\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npm25 <- read_csv(here::here(\"week6\", \"daily_pm25_LA.csv\")) %>% \n  janitor::clean_names() %>%  \n  mutate(date = mdy(date))\n```\n:::\n\n\n\n\nWe will also be using daily precipitation data from a NOAA API. After following the Pre Lab Prep instructions to request an API Key, paste the key that was sent to your email in the designated area below. \n\n\n::: {.cell}\n\n```{.r .cell-code}\noptions(noaakey = \"YOUR-NOAA-TOKEN-HERE\")\n```\n:::\n\n\n\n\n::: {.cell}\n\n:::\n\n\nNow we pull daily precipitation data from a NOAA weather station in Downtown LA for all of 2023.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get data for stations\nprecip_raw <- ghcnd_search(\n    stationid = \"USC00045933\", # Downtown LA Station\n    var = \"PRCP\",\n    date_min = \"2023-01-01\",\n    date_max = \"2023-12-31\"\n  ) %>%\n  pluck(\"prcp\") %>%                  # Extract the prcp data frame \n  select(id, date, prcp) %>%\n  mutate(date = as.Date(date))\n\n# 3. Quick Summary\nsummary(precip_raw)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      id                 date                 prcp       \n Length:365         Min.   :2023-01-01   Min.   :  0.00  \n Class :character   1st Qu.:2023-04-02   1st Qu.:  0.00  \n Mode  :character   Median :2023-07-02   Median :  0.00  \n                    Mean   :2023-07-02   Mean   : 26.04  \n                    3rd Qu.:2023-10-01   3rd Qu.:  0.00  \n                    Max.   :2023-12-31   Max.   :513.00  \n```\n\n\n:::\n:::\n\n\n#### Get Google trends data on respitory illness\n\nGoogle Trends provides a weekly index (0–100) of relative search interest. We query the term **\"asthma inhaler\"** for the Los Angeles Designated Market Area (DMA code `US-CA-803`) in 2023.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Query Google Trends for California\ntrends <- gtrends(\n  keyword = \"asthma inhaler\",\n  geo = \"US-CA-803\",# LA code\n  time = \"2023-01-01 2023-12-31\",\n  onlyInterest = TRUE\n)\n\ntrends_df <- trends$interest_over_time %>%\n  select(date, hits) %>%\n  mutate(\n    date = as.Date(date),\n    asthma_index = as.numeric(hits)\n  ) %>%\n  filter(!is.na(asthma_index)) %>%\n  select(date, asthma_index)\n```\n:::\n\n\n\n\n\n## Data Cleaning\n\nNow we clean the precipitation data (converting units and removing error codes) and merge all three datasets.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprecip <- precip_raw %>%\n  filter(!is.na(prcp)) %>% \n  mutate(\n    precip_in = prcp / 254,           # Convert to inches\n    precip_in = ifelse(precip_in < 0, 0, precip_in)  # Remove any error codes\n  ) %>%\n  select(station_id = id, date, precip_in)\n\n\n# Merge data\ndata <- pm25 %>%\n  left_join(\n    precip %>% select(station_id, date, precip_in),\n    by = \"date\"\n  ) %>%\n  filter(!is.na(precip_in))\n```\n:::\n\n\nSince Google Trends data is reported weekly, we need to aggregate our daily PM2.5 and precipitation data to the **weekly** level before merging.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Aggregate data to weekly (since google trends is weekly)\n\n\n# Create week variable (Sunday start)\ndata <- data %>%\n  mutate(week_start = floor_date(date, \"week\", week_start = 7))\n\n# Aggregate to county-week level\ndata_weekly <- data %>%\n  group_by(week_start) %>%\n  summarise(\n    pm25_mean = mean(daily_mean_pm2_5_concentration, na.rm= TRUE),\n    precip_total = sum(precip_in),\n    .groups = \"drop\"\n  ) \n\n\n# Merge with Google Trends\ndata_weekly_joined <- data_weekly %>%\n  left_join(trends_df, by = c(\"week_start\" = \"date\")) %>%\n  filter(!is.na(asthma_index))\n```\n:::\n\n\nLet's inspect our final analysis dataset:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(data_weekly_joined)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 53\nColumns: 4\n$ week_start   <date> 2023-01-01, 2023-01-08, 2023-01-15, 2023-01-22, 2023-01-…\n$ pm25_mean    <dbl> 7.300000, 9.088235, 7.211765, 9.664706, 8.576471, 9.35263…\n$ precip_total <dbl> 6.6850394, 13.6338583, 4.1574803, 0.0000000, 1.7086614, 5…\n$ asthma_index <dbl> 43, 68, 69, 42, 66, 75, 90, 54, 74, 75, 73, 82, 55, 62, 7…\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(data_weekly_joined)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   week_start           pm25_mean       precip_total     asthma_index   \n Min.   :2023-01-01   Min.   : 6.820   Min.   : 0.000   Min.   : 35.00  \n 1st Qu.:2023-04-02   1st Qu.: 8.433   1st Qu.: 0.000   1st Qu.: 53.00  \n Median :2023-07-02   Median :10.325   Median : 0.000   Median : 66.00  \n Mean   :2023-07-02   Mean   :11.028   Mean   : 1.595   Mean   : 63.11  \n 3rd Qu.:2023-10-01   3rd Qu.:12.994   3rd Qu.: 1.709   3rd Qu.: 75.00  \n Max.   :2023-12-31   Max.   :20.271   Max.   :13.634   Max.   :100.00  \n```\n\n\n:::\n:::\n\n\n:::{.callout-tip title = \"Comprehension Check}\nHow many observations do we have in our final dataset? Is this a lot or a little for regression analysis? What implications does a small sample size have for our estimates?\n:::\n\n\n## Exploratory Data Analysis\n\nBefore diving into models, let's visualize our three key variables and their relationships.\n\n\n#### Relationship Between PM2.5 and Asthma Searches (the relationship we want to estimate)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data_weekly_joined, aes(x = pm25_mean, y = asthma_index)) +\n  geom_point(alpha = 0.6, color = \"darkgreen\", size = 2) +\n  geom_smooth(method = \"lm\", se = TRUE, color = \"dodgerblue\", linewidth = 1) +\n  labs(\n    x = \"Weekly Mean PM 2.5 (AQI)\",\n    y = \"Asthma Inhaler Search Index\",\n    title = \"PM 2.5 vs. Asthma Inhaler Searches\"\n  ) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](week6_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n#### Relationship Between Precipitation and PM2.5 (first-stage relationship)\n\nThis is the key relationship for our instrument. Does more rain lead to lower PM2.5?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data_weekly_joined, aes(x = precip_total, y = pm25_mean)) +\n  geom_point(alpha = 0.6, color = \"darkgreen\", size = 2) +\n  geom_smooth(method = \"lm\", se = TRUE, color = \"dodgerblue\", linewidth = 1) +\n  labs(\n    x = \"Weekly Total Precipitation (in)\",\n    y = \"Weekly Mean PM 2.5 (AQI)\",\n    title = \"Precipitation vs. PM2.5\"\n  ) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](week6_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n\n## Model\n\n### Step 1: OLS\n\nWe start with a simple OLS regression — regressing asthma search interest on PM2.5 with no controls. This gives us the *unadjusted* association, which we expect to be biased.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm1_ols <- lm(asthma_index ~ pm25_mean, data = data_weekly_joined)\n\nsummary(m1_ols)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = asthma_index ~ pm25_mean, data = data_weekly_joined)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-28.145 -10.530   3.011  11.797  35.956 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  60.5204     7.2912   8.300 4.94e-11 ***\npm25_mean     0.2351     0.6324   0.372    0.712    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 15.48 on 51 degrees of freedom\nMultiple R-squared:  0.002703,\tAdjusted R-squared:  -0.01685 \nF-statistic: 0.1382 on 1 and 51 DF,  p-value: 0.7116\n```\n\n\n:::\n:::\n\n\n**Interpretation**: The coefficient on `pm25_mean` tells us the estimated change in the asthma inhaler search index associated with a one-unit increase in weekly mean AQI. But remember — this estimate is likely biased due to omitted variables.\n\n\n\n### Step 2: OLS with Month Fixed Effects\n\nWe add month fixed effects to control for seasonal confounders (e.g., flu season, wildfire season, holiday patterns).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm2_ols_fe <-lm(asthma_index ~ pm25_mean + factor(month(week_start)) ,\n             data = data_weekly_joined)\nsummary(m2_ols_fe)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = asthma_index ~ pm25_mean + factor(month(week_start)), \n    data = data_weekly_joined)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-32.327 -10.493   1.336  10.810  30.200 \n\nCoefficients:\n                            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                  52.1878    10.4359   5.001 1.18e-05 ***\npm25_mean                     0.6468     0.9084   0.712    0.481    \nfactor(month(week_start))2   15.8474    10.7288   1.477    0.147    \nfactor(month(week_start))3   14.0945    10.7434   1.312    0.197    \nfactor(month(week_start))4    2.5608    10.7699   0.238    0.813    \nfactor(month(week_start))5   -3.8914    10.9415  -0.356    0.724    \nfactor(month(week_start))6    7.4701    10.8045   0.691    0.493    \nfactor(month(week_start))7   -0.7651    11.9733  -0.064    0.949    \nfactor(month(week_start))8   -3.4961    11.0509  -0.316    0.753    \nfactor(month(week_start))9    8.5553    11.5725   0.739    0.464    \nfactor(month(week_start))10   7.9187    10.6074   0.747    0.460    \nfactor(month(week_start))11  -3.6829    10.7354  -0.343    0.733    \nfactor(month(week_start))12   2.5709    10.9704   0.234    0.816    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 15.99 on 40 degrees of freedom\nMultiple R-squared:  0.1657,\tAdjusted R-squared:  -0.08463 \nF-statistic: 0.6619 on 12 and 40 DF,  p-value: 0.7762\n```\n\n\n:::\n:::\n\n\n:::{.callout-tip title=\"Comprehension Check\"}\n1. How did the coefficient on `pm25_mean` change when we added month fixed effects? What does this tell you about the role of seasonal confounders?\n2. Even with month fixed effects, why might the OLS estimate still be biased? What sources of endogeneity remain?\n:::\n\n\n### Step 3: First Stage — Does Precipitation Predict PM2.5?\n\nNow we move to the IV approach. The first step in 2SLS is to verify that our instrument ($Z$ = precipitation) is a strong predictor of the endogenous variable ($X$ = PM2.5).\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfirst_stage <- lm(pm25_mean ~ precip_total + factor(month(week_start)), \n                  data = data_weekly_joined)\n\nexport_summs(first_stage, digits = 3,\n             model.names = c(\"First stage: Average PM 2.5\"),\n             coefs = c(\"(Intercept)\", \"precip_total\")) \n```\n\n::: {.cell-output-display}\n\n```{=html}\n<table class=\"huxtable\" data-quarto-disable-processing=\"true\"  style=\"margin-left: auto; margin-right: auto;\">\n<col><col><thead>\n<tr>\n<th class=\"huxtable-cell huxtable-header\" style=\"text-align: center;  border-style: solid solid solid solid; border-width: 0.8pt 0pt 0pt 0pt;      font-weight: normal;\"></th><th class=\"huxtable-cell huxtable-header\" style=\"text-align: center;  border-style: solid solid solid solid; border-width: 0.8pt 0pt 0.4pt 0pt;      font-weight: normal;\">First stage: Average PM 2.5</th></tr>\n</thead>\n<tbody>\n<tr>\n<th class=\"huxtable-cell huxtable-header\" style=\"border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt;      font-weight: normal;\">(Intercept)</th><td class=\"huxtable-cell\" style=\"text-align: right;  border-style: solid solid solid solid; border-width: 0.4pt 0pt 0pt 0pt;\">8.893 ***</td></tr>\n<tr>\n<th class=\"huxtable-cell huxtable-header\" style=\"border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt;      font-weight: normal;\"></th><td class=\"huxtable-cell\" style=\"text-align: right;  border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt;\">(1.559)&nbsp;&nbsp;&nbsp;</td></tr>\n<tr>\n<th class=\"huxtable-cell huxtable-header\" style=\"border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt;      font-weight: normal;\">precip_total</th><td class=\"huxtable-cell\" style=\"text-align: right;  border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt;\">-0.100&nbsp;&nbsp;&nbsp;&nbsp;</td></tr>\n<tr>\n<th class=\"huxtable-cell huxtable-header\" style=\"border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt;      font-weight: normal;\"></th><td class=\"huxtable-cell\" style=\"text-align: right;  border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt;\">(0.181)&nbsp;&nbsp;&nbsp;</td></tr>\n<tr>\n<th class=\"huxtable-cell huxtable-header\" style=\"border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt;      font-weight: normal;\">N</th><td class=\"huxtable-cell\" style=\"text-align: right;  border-style: solid solid solid solid; border-width: 0.4pt 0pt 0pt 0pt;\">53&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td></tr>\n<tr>\n<th class=\"huxtable-cell huxtable-header\" style=\"border-style: solid solid solid solid; border-width: 0pt 0pt 0.8pt 0pt;      font-weight: normal;\">R2</th><td class=\"huxtable-cell\" style=\"text-align: right;  border-style: solid solid solid solid; border-width: 0pt 0pt 0.8pt 0pt;\">0.487&nbsp;&nbsp;&nbsp;&nbsp;</td></tr>\n<tr>\n<th class=\"huxtable-cell huxtable-header\" colspan=\"2\" style=\"border-style: solid solid solid solid; border-width: 0.8pt 0pt 0pt 0pt;      font-weight: normal;\">*** p &lt; 0.001; ** p &lt; 0.01; * p &lt; 0.05.</th></tr>\n</tbody>\n</table>\n\n```\n\n:::\n:::\n\n\n**Assessing instrument strength**: A common rule of thumb is that the **F-statistic** on the excluded instrument(s) in the first stage should be greater than 10. An F-stat below 10 suggests a **weak instrument**, which can lead to biased IV estimates and unreliable inference.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Extract the F-statistic for instrument strength\nfirst_stage_summary <- summary(first_stage)\n\nfirst_stage_summary$fstatistic[1]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   value \n3.164229 \n```\n\n\n:::\n:::\n\n\n:::{.callout-tip title=\"Comprehension Check\"}\n1. What is the sign of the coefficient on `precip_total` in the first stage? Is this consistent with your expectations about how precipitation affects PM2.5?\n2. Based on the first-stage results, would you consider precipitation a strong or weak instrument? \n:::\n\n### Step 4: Second Stage (Manual 2SLS)\n\nUsing the predicted values ($\\hat{X}$) from the first stage, we now estimate the second stage. This isolates the variation in PM 2.5 that is driven *only* by precipitation ($Z$).\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_weekly_joined$pm25_hat <- predict(first_stage)\n\nsecond_stage <- lm(asthma_index ~ pm25_hat + factor(month(week_start)), \n                   data = data_weekly_joined)\n\nexport_summs(second_stage, digits = 3, \n             model.names = c(\"Second stage: Asthma Index\"),\n             coefs = c(\"(Intercept)\", \"pm25_hat\"))\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<table class=\"huxtable\" data-quarto-disable-processing=\"true\"  style=\"margin-left: auto; margin-right: auto;\">\n<col><col><thead>\n<tr>\n<th class=\"huxtable-cell huxtable-header\" style=\"text-align: center;  border-style: solid solid solid solid; border-width: 0.8pt 0pt 0pt 0pt;      font-weight: normal;\"></th><th class=\"huxtable-cell huxtable-header\" style=\"text-align: center;  border-style: solid solid solid solid; border-width: 0.8pt 0pt 0.4pt 0pt;      font-weight: normal;\">Second stage: Asthma Index</th></tr>\n</thead>\n<tbody>\n<tr>\n<th class=\"huxtable-cell huxtable-header\" style=\"border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt;      font-weight: normal;\">(Intercept)</th><td class=\"huxtable-cell\" style=\"text-align: right;  border-style: solid solid solid solid; border-width: 0.4pt 0pt 0pt 0pt;\">114.038&nbsp;</td></tr>\n<tr>\n<th class=\"huxtable-cell huxtable-header\" style=\"border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt;      font-weight: normal;\"></th><td class=\"huxtable-cell\" style=\"text-align: right;  border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt;\">(87.383)</td></tr>\n<tr>\n<th class=\"huxtable-cell huxtable-header\" style=\"border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt;      font-weight: normal;\">pm25_hat</th><td class=\"huxtable-cell\" style=\"text-align: right;  border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt;\">-6.744&nbsp;</td></tr>\n<tr>\n<th class=\"huxtable-cell huxtable-header\" style=\"border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt;      font-weight: normal;\"></th><td class=\"huxtable-cell\" style=\"text-align: right;  border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt;\">(10.407)</td></tr>\n<tr>\n<th class=\"huxtable-cell huxtable-header\" style=\"border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt;      font-weight: normal;\">N</th><td class=\"huxtable-cell\" style=\"text-align: right;  border-style: solid solid solid solid; border-width: 0.4pt 0pt 0pt 0pt;\">53&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td></tr>\n<tr>\n<th class=\"huxtable-cell huxtable-header\" style=\"border-style: solid solid solid solid; border-width: 0pt 0pt 0.8pt 0pt;      font-weight: normal;\">R2</th><td class=\"huxtable-cell\" style=\"text-align: right;  border-style: solid solid solid solid; border-width: 0pt 0pt 0.8pt 0pt;\">0.164&nbsp;</td></tr>\n<tr>\n<th class=\"huxtable-cell huxtable-header\" colspan=\"2\" style=\"border-style: solid solid solid solid; border-width: 0.8pt 0pt 0pt 0pt;      font-weight: normal;\">*** p &lt; 0.001; ** p &lt; 0.01; * p &lt; 0.05.</th></tr>\n</tbody>\n</table>\n\n```\n\n:::\n:::\n\n\n:::{.callout-warning}\nRemember: the standard errors from this manual second stage are not correct for inference. They don't account for the estimation uncertainty in $\\hat{X}$ from the first stage. Use `ivreg()` for your actual results.\n:::\n\n\n### Step 5: IV Estimation with `ivreg()`\n\nThe `ivreg()` function performs 2SLS in one step with **correct standard errors**. The syntax uses `|` to separate the structural equation (left) from the instruments (right).\n\nThe formula syntax is: `Y ~ D + controls | Z + controls`\n\n- Everything to the **left** of `|` is in the second-stage equation (outcome $Y$ regressed on endogenous variable $X$ and controls).\n- Everything to the **right** of `|` lists the instruments ($Z$) and exogenous controls used in the first stage.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm3_ivreg <- ivreg(asthma_index ~ pm25_mean + factor(month(week_start)) | \n                  precip_total + factor(month(week_start)), \n                  data = data_weekly_joined)\n\nexport_summs(m3_ivreg, digits = 3,\n             model.names = c(\"IV Regression (ivreg)\"),\n             coefs = c(\"pm25_mean\"))\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<table class=\"huxtable\" data-quarto-disable-processing=\"true\"  style=\"margin-left: auto; margin-right: auto;\">\n<col><col><thead>\n<tr>\n<th class=\"huxtable-cell huxtable-header\" style=\"text-align: center;  border-style: solid solid solid solid; border-width: 0.8pt 0pt 0pt 0pt;      font-weight: normal;\"></th><th class=\"huxtable-cell huxtable-header\" style=\"text-align: center;  border-style: solid solid solid solid; border-width: 0.8pt 0pt 0.4pt 0pt;      font-weight: normal;\">IV Regression (ivreg)</th></tr>\n</thead>\n<tbody>\n<tr>\n<th class=\"huxtable-cell huxtable-header\" style=\"border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt;      font-weight: normal;\">pm25_mean</th><td class=\"huxtable-cell\" style=\"text-align: right;  border-style: solid solid solid solid; border-width: 0.4pt 0pt 0pt 0pt;\">-6.744&nbsp;</td></tr>\n<tr>\n<th class=\"huxtable-cell huxtable-header\" style=\"border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt;      font-weight: normal;\"></th><td class=\"huxtable-cell\" style=\"text-align: right;  border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt;\">(16.940)</td></tr>\n<tr>\n<th class=\"huxtable-cell huxtable-header\" style=\"border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt;      font-weight: normal;\">nobs</th><td class=\"huxtable-cell\" style=\"text-align: right;  border-style: solid solid solid solid; border-width: 0.4pt 0pt 0pt 0pt;\">53&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td></tr>\n<tr>\n<th class=\"huxtable-cell huxtable-header\" style=\"border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt;      font-weight: normal;\">r.squared</th><td class=\"huxtable-cell\" style=\"text-align: right;  border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt;\">-1.215&nbsp;</td></tr>\n<tr>\n<th class=\"huxtable-cell huxtable-header\" style=\"border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt;      font-weight: normal;\">adj.r.squared</th><td class=\"huxtable-cell\" style=\"text-align: right;  border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt;\">-1.880&nbsp;</td></tr>\n<tr>\n<th class=\"huxtable-cell huxtable-header\" style=\"border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt;      font-weight: normal;\">sigma</th><td class=\"huxtable-cell\" style=\"text-align: right;  border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt;\">26.052&nbsp;</td></tr>\n<tr>\n<th class=\"huxtable-cell huxtable-header\" style=\"border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt;      font-weight: normal;\">statistic</th><td class=\"huxtable-cell\" style=\"text-align: right;  border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt;\">0.247&nbsp;</td></tr>\n<tr>\n<th class=\"huxtable-cell huxtable-header\" style=\"border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt;      font-weight: normal;\">p.value</th><td class=\"huxtable-cell\" style=\"text-align: right;  border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt;\">0.994&nbsp;</td></tr>\n<tr>\n<th class=\"huxtable-cell huxtable-header\" style=\"border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt;      font-weight: normal;\">df</th><td class=\"huxtable-cell\" style=\"text-align: right;  border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt;\">13.000&nbsp;</td></tr>\n<tr>\n<th class=\"huxtable-cell huxtable-header\" style=\"border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt;      font-weight: normal;\">df.residual</th><td class=\"huxtable-cell\" style=\"text-align: right;  border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt;\">40.000&nbsp;</td></tr>\n<tr>\n<th class=\"huxtable-cell huxtable-header\" style=\"border-style: solid solid solid solid; border-width: 0pt 0pt 0.8pt 0pt;      font-weight: normal;\">nobs.1</th><td class=\"huxtable-cell\" style=\"text-align: right;  border-style: solid solid solid solid; border-width: 0pt 0pt 0.8pt 0pt;\">53.000&nbsp;</td></tr>\n<tr>\n<th class=\"huxtable-cell huxtable-header\" colspan=\"2\" style=\"border-style: solid solid solid solid; border-width: 0.8pt 0pt 0pt 0pt;      font-weight: normal;\">*** p &lt; 0.001; ** p &lt; 0.01; * p &lt; 0.05.</th></tr>\n</tbody>\n</table>\n\n```\n\n:::\n:::\n\n\n### Step 6: Comparing All Models\n\nLet's compare the OLS, OLS + FE, and IV estimates side by side.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexport_summs(m1_ols, m2_ols_fe, m3_ivreg,\n             digits = 3,\n             model.names = c(\"OLS (Naive)\", \"OLS + Month FE\", \"IV (2SLS)\"),\n             coefs = c(\"pm25_mean\"))\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<table class=\"huxtable\" data-quarto-disable-processing=\"true\"  style=\"margin-left: auto; margin-right: auto;\">\n<col><col><col><col><thead>\n<tr>\n<th class=\"huxtable-cell huxtable-header\" style=\"text-align: center;  border-style: solid solid solid solid; border-width: 0.8pt 0pt 0pt 0pt;      font-weight: normal;\"></th><th class=\"huxtable-cell huxtable-header\" style=\"text-align: center;  border-style: solid solid solid solid; border-width: 0.8pt 0pt 0.4pt 0pt;      font-weight: normal;\">OLS (Naive)</th><th class=\"huxtable-cell huxtable-header\" style=\"text-align: center;  border-style: solid solid solid solid; border-width: 0.8pt 0pt 0.4pt 0pt;      font-weight: normal;\">OLS + Month FE</th><th class=\"huxtable-cell huxtable-header\" style=\"text-align: center;  border-style: solid solid solid solid; border-width: 0.8pt 0pt 0.4pt 0pt;      font-weight: normal;\">IV (2SLS)</th></tr>\n</thead>\n<tbody>\n<tr>\n<th class=\"huxtable-cell huxtable-header\" style=\"border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt;      font-weight: normal;\">pm25_mean</th><td class=\"huxtable-cell\" style=\"text-align: right;  border-style: solid solid solid solid; border-width: 0.4pt 0pt 0pt 0pt;\">0.235&nbsp;</td><td class=\"huxtable-cell\" style=\"text-align: right;  border-style: solid solid solid solid; border-width: 0.4pt 0pt 0pt 0pt;\">0.647&nbsp;</td><td class=\"huxtable-cell\" style=\"text-align: right;  border-style: solid solid solid solid; border-width: 0.4pt 0pt 0pt 0pt;\">-6.744&nbsp;</td></tr>\n<tr>\n<th class=\"huxtable-cell huxtable-header\" style=\"border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt;      font-weight: normal;\"></th><td class=\"huxtable-cell\" style=\"text-align: right;  border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt;\">(0.632)</td><td class=\"huxtable-cell\" style=\"text-align: right;  border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt;\">(0.908)</td><td class=\"huxtable-cell\" style=\"text-align: right;  border-style: solid solid solid solid; border-width: 0pt 0pt 0.4pt 0pt;\">(16.940)</td></tr>\n<tr>\n<th class=\"huxtable-cell huxtable-header\" style=\"border-style: solid solid solid solid; border-width: 0pt 0pt 0pt 0pt;      font-weight: normal;\">N</th><td class=\"huxtable-cell\" style=\"text-align: right;  border-style: solid solid solid solid; border-width: 0.4pt 0pt 0pt 0pt;\">53&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td><td class=\"huxtable-cell\" style=\"text-align: right;  border-style: solid solid solid solid; border-width: 0.4pt 0pt 0pt 0pt;\">53&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td><td class=\"huxtable-cell\" style=\"text-align: right;  border-style: solid solid solid solid; border-width: 0.4pt 0pt 0pt 0pt;\">53&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td></tr>\n<tr>\n<th class=\"huxtable-cell huxtable-header\" style=\"border-style: solid solid solid solid; border-width: 0pt 0pt 0.8pt 0pt;      font-weight: normal;\">R2</th><td class=\"huxtable-cell\" style=\"text-align: right;  border-style: solid solid solid solid; border-width: 0pt 0pt 0.8pt 0pt;\">0.003&nbsp;</td><td class=\"huxtable-cell\" style=\"text-align: right;  border-style: solid solid solid solid; border-width: 0pt 0pt 0.8pt 0pt;\">0.166&nbsp;</td><td class=\"huxtable-cell\" style=\"text-align: right;  border-style: solid solid solid solid; border-width: 0pt 0pt 0.8pt 0pt;\">-1.215&nbsp;</td></tr>\n<tr>\n<th class=\"huxtable-cell huxtable-header\" colspan=\"4\" style=\"border-style: solid solid solid solid; border-width: 0.8pt 0pt 0pt 0pt;      font-weight: normal;\">*** p &lt; 0.001; ** p &lt; 0.01; * p &lt; 0.05.</th></tr>\n</tbody>\n</table>\n\n```\n\n:::\n:::\n\n\n# Discussion & Reflection\n\n:::{.callout-tip title=\"Comprehension Check\"}\n\n\n1. **Validity of the instrument**: We argued that precipitation satisfies the exclusion restriction because it affects asthma searches only through PM2.5. Can you think of a mechanism by which precipitation could *directly* affect asthma searches, bypassing PM2.5? If such a relationship exists, how would it bias our IV estimate?\n\n\n2. **LATE interpretation**: IV estimates capture the **Local Average Treatment Effect (LATE)** — the effect for \"compliers,\" i.e., observations whose PM2.5 levels are actually moved by changes in precipitation. Who are the \"compliers\" in this setting, and how might this affect the generalizability of our estimate?\n\n3. **Alternative instruments**: Can you propose another variable that might serve as an instrument for PM2.5? Explain why it would satisfy relevance and the exclusion restriction.\n\n\n4. **Four key assumptions**:  List the four key assumptions required for the IV strategy (2SLS) to identify a causal effect, and briefly explain what each one means in the context of this study.\n:::\n\n",
    "supporting": [
      "week6_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}